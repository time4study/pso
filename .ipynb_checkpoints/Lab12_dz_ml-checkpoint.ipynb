{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.multiclass\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maszynowe Uczenie\n",
    "\n",
    "Powyżej wczytano najistotniejsze moduły biblioteki *scikit-learn* używanej do maszynowego uczenia w Pythonie. Całe API można znaleźć tutaj:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/classes.html\n",
    "\n",
    "Poza tym, warto też zaglądać do:\n",
    "\n",
    "http://scikit-learn.org/stable/user_guide.html\n",
    "\n",
    "Na początku, wczytaj i przejrzyj bazę cyfr wczytywaną metodą *sklearn.datasets.load_digits()*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytaj bazę ponownie ustawiając argument *return_X_y* na *True*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Narysuj kilka przykładowych obrazków z bazy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział danych na testowe i treningowe\n",
    "\n",
    "Można to łatwo osiągnąć używając metody *sklearn.model_selection.train_test_split()*. Argument *test_size* pozwala na ustalenie procentu danych jakie mają tworzyć w dane testowe.\n",
    "\n",
    "Podziel losowo zbiór na dane treningowe (90%) i testowe (10%) i narysuj histogram klas w danych testowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratyfikacja\n",
    "\n",
    "Scikit-learn ma bardzo wygodne klasy umożliwiające na stratyfikację podziału danych, czyli zapewnienie że ilość klas będzie równomierna. Użyj klasy *sklearn.model_selection.StratifiedShuffleSplit* żeby podzielić dane tak jak wyżej. Klasa ta może wygenerować kilka podziałów, ale dla naszej potrzeby wystarczy ustawić *n_splits* na 1. To co zwraca metoda *split* tej klasy jest generatorem (specjalna rodzaj Pythonowego objektu nadająca się do użycia w pętlach), ale można użyć metdoty *next* żeby wyciągnąć pierwszy (i jedyny) element tego generatora.\n",
    "\n",
    "Wygeneruj stratyfikowany podział danych jak wyżej i wylicz histogram klas testowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja\n",
    "\n",
    "Użyjemy tutaj bardzo prostego modelu liniowego o nazwie \"regresja logistyczna\". Klasa *sklearn.linear_model.LogisticRegression* ma wiele parametrów, ale możemy je na razie zostawić domyślne.\n",
    "\n",
    "Użyj metody *fit* podając do niej dane treningowe, a potem metodę *predict* podając dane testowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja\n",
    "\n",
    "Moduł *sklearn.metrics* zawiera mnóstwo metod ewaluacji danych, ale trzeba dobrze rozumieć co one oznaczają. Niektóre z nich można policzyć tylko dla niektórych metod klasyfikacji, wiec warto pocztać dokumentację i dobrze sprawdzić wyjątki jak coś pójdzie nie tak.\n",
    "\n",
    "Najprostszą (i z pewnością działającą dla największej liczby przypadków) miarą jest *sklearn.metrics.accuracy_score*. Policz ją dla uzyskanego wyżej wyniku.\n",
    "\n",
    "Możesz też policzć miary typu precision/recall/F1, ale one działają tylko dla problemów binarnych. Można ją jednak zastosować dla naszego problemu rozważająć każdą klasę osobno i uśredniając wynik. Do tego należy użyć parametru *average* i podać do niego wartości *micro*, *macro* lub *weighted*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macierz konfuzji\n",
    "\n",
    "Do analizy błędów warto czasami zajrzeć do macierzy pomyłek. Wyświetl i narysuj macierz używając metody *sklearn.metrics.confusion_matrix*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Dla małych zbiorów danych, bardziej przecyzyjny wynik można uzyskać używając procedury walidacji krzyżowej. W scikit-learn mamy do tego metodę *sklearn.model_selection.KFold*, albo jeszcze lepiej *sklearn.model_selection.StratifiedKFold*.\n",
    "\n",
    "Stwórz obiekt tej klasy do wykonania walidacji 5-krzyżowej i w pętli for powtórz powyższy eksperyment zapisując miarę jakości dla każdego folda, a na końcu podaj jego średnią i odchylenie standardowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krzywa ROC\n",
    "\n",
    "Krzywę tą też można wyliczyć tylko dla problemów binarnych. Dlatego musimy użyc podobnej metody \"uśredniania\" wyników jak w przypadku precision/recall. Dodatkowo, metoda ta jest o wiele bardziej precyzyjna jeśli wynikiem jest dokładna miara prawdopodbieństwa, zamiast binarnej klasy. Umożliwia nam ona ustalenie wartości progowej zależnej od wartości prawdopodobieństwa.\n",
    "\n",
    "Wytrenuj ponownie model do regresji logistycznej (jak wyżej), ale tym razem użyj funkcji *decision_funcion* zamiast *predict* żeby otrzymać bardziej szczegółowy wynik klasyfikacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli chcemy porównać ten wynik z etykietami refencji, musimy je najpierw zmienić do postaci binarnej. Można do tego użyć metody *sklearn.preprocessing.label_binarize*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tej chwili można wyliczyć krzywę ROC dla dowolnej klasy używając metodę *sklearn.metrics.roc_curve* i podając do niej wyniki dla wybranej klasy. Metoda ta zwraca trzy wartości, z których nas interesują tylko pierwsze dwie. Wartości te można podać zarówno do metody *plot*, jak i do metody *sklearn.metrics.auc* żeby wyliczyć miarę AUC danej krzywej. Narsyuj też na wykresie krzywą od (0,0) do (1,1) reprezentującą odcięcie klasyfikacji losowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można też narysować uśredniony wykres dla wszystkich klas (tzw. metodą \"micro\") używając funkcji *ravel()* dla macierzy wyniku i referencji.\n",
    "\n",
    "Więcej informacji znajdziesz na stronie: http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca domowa\n",
    "\n",
    "Wybierz kilka (minimum 3!) różnych klasyfikatorów do problemów typu *multi-class* z tej strony: http://scikit-learn.org/stable/modules/multiclass.html - najlepiej spróbować zarówno *One-vs-all* jak i *One-vs-one* żeby zobaczyć który jest lepszy.\n",
    "\n",
    "Wylicz i porównaj ich zarówno pod względem *accuracy* wyliczonego z walidacji krzyżowej jak i krzywych ROC. Wyniki podaj zarówno w postaci listy średnych i odchylenia *accuracy* oraz AUC, jak i w postaci wykresów: liniowych dla krzywych ROC (wszystkie klasyfikatory na jednym wykresie!) oraz *boxplot* dla miar *accuracy* (też wszystkie na jednym).\n",
    "\n",
    "## Alternatywna praca domowa\n",
    "\n",
    "Wylicz wynik klasyfikacji na innym zbiorze obrazów. Może to być oryginalny MNIST, CIFAR-10 lub coś innego podobnie złożonego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
